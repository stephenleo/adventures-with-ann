{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from opensearchpy.helpers import bulk\n",
    "import boto3\n",
    "import requests\n",
    "import polling2\n",
    "import logging\n",
    "from random import randint\n",
    "\n",
    "# Setup Basic Configuration\n",
    "POLL = 60\n",
    "logging.addLevelName(POLL, 'POLL')\n",
    "\n",
    "logging.basicConfig(level=POLL,\n",
    "                    format='%(asctime)s %(levelname)s: %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "logging.getLogger().setLevel(POLL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pull_date</th>\n",
       "      <th>brand</th>\n",
       "      <th>article_id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>estimatedPublishedDate</th>\n",
       "      <th>embedding</th>\n",
       "      <th>anti_trans_legislation</th>\n",
       "      <th>covid_19</th>\n",
       "      <th>cybersecurity</th>\n",
       "      <th>data_privacy_gdpr</th>\n",
       "      <th>diversity_inclusion</th>\n",
       "      <th>gen_z</th>\n",
       "      <th>inflation</th>\n",
       "      <th>minimum_wage</th>\n",
       "      <th>ukraine_russia</th>\n",
       "      <th>vaccine</th>\n",
       "      <th>waste_reduction</th>\n",
       "      <th>work_from_home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46679408493_6_Volkswagen</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>46679408493</td>\n",
       "      <td>12/13/2021 – Volkswagen was given a new €235.0...</td>\n",
       "      <td>Volkswagen (VOW3) – Analysts’ Weekly Ratings C...</td>\n",
       "      <td>2022-01-01 00:22:41</td>\n",
       "      <td>[0.07120183110237122, 0.09447652101516724, 0.0...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46679425484_7_PayPal</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>46679425484</td>\n",
       "      <td>PayPal Company Profile</td>\n",
       "      <td>PayPal Holdings, Inc. (NASDAQ:PYPL) is Pelham ...</td>\n",
       "      <td>2022-01-01 00:28:42</td>\n",
       "      <td>[-0.019512677565217018, -0.021549265831708908,...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id   pull_date       brand   article_id  \\\n",
       "0  46679408493_6_Volkswagen  2022-04-04  Volkswagen  46679408493   \n",
       "1      46679425484_7_PayPal  2022-01-02      PayPal  46679425484   \n",
       "\n",
       "                                                text  \\\n",
       "0  12/13/2021 – Volkswagen was given a new €235.0...   \n",
       "1                             PayPal Company Profile   \n",
       "\n",
       "                                               title estimatedPublishedDate  \\\n",
       "0  Volkswagen (VOW3) – Analysts’ Weekly Ratings C...    2022-01-01 00:22:41   \n",
       "1  PayPal Holdings, Inc. (NASDAQ:PYPL) is Pelham ...    2022-01-01 00:28:42   \n",
       "\n",
       "                                           embedding  anti_trans_legislation  \\\n",
       "0  [0.07120183110237122, 0.09447652101516724, 0.0...                   False   \n",
       "1  [-0.019512677565217018, -0.021549265831708908,...                   False   \n",
       "\n",
       "   covid_19  cybersecurity  data_privacy_gdpr  diversity_inclusion  gen_z  \\\n",
       "0     False          False              False                False  False   \n",
       "1     False          False              False                False  False   \n",
       "\n",
       "   inflation  minimum_wage  ukraine_russia  vaccine  waste_reduction  \\\n",
       "0      False         False           False    False            False   \n",
       "1      False         False           False    False            False   \n",
       "\n",
       "   work_from_home  \n",
       "0           False  \n",
       "1           False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = pd.read_pickle('s3://trust-stream-nlp-data/trust-content-dsml/chunk_embedding_with_topic_sample_test.pkl')\n",
    "articles = articles.rename(columns={'paragraph_id': 'id', 'minilm_embeddings': 'embedding'})\n",
    "\n",
    "print(articles.shape)\n",
    "articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opensearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"search-mynewdomain-gp74byna6ivfgazl4upbhbclfe.us-east-1.es.amazonaws.com\"\n",
    "port = 443\n",
    "region = 'us-east-1'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, region)\n",
    "\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': host, 'port': port}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ip            heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name\n",
      "x.x.x.x           34          97   4    0.13    0.37     0.48 dimr      -      829c6120268cba75b105aebe5ded58f8\n",
      "x.x.x.x           72          97   4    0.15    0.25     0.22 dimr      -      9def54968eaed1446cc87cfc0d17a082\n",
      "x.x.x.x            11          97   4    0.37    0.62     0.50 dimr      *      0fa9a767a70fd6dc523b62929e3b8da1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = f'https://{host}:{port}/_cat/nodes?v'\n",
    "response = requests.get(url, auth=auth)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'health status index              uuid                   pri rep docs.count docs.deleted store.size pri.store.size\\ngreen  open   article_chunks     OoKSWT4ZRwuJoLvDcbeZVw   4   1          0            0      1.6kb           852b\\ngreen  open   chunk_texts_index  p3e-yfCaQQ6HiMRR--4xzQ  10   0    3885306            0     39.7gb         39.7gb\\ngreen  open   python-test-index3 zghM9fXRSJG_K8Nb5xJCOQ   4   1          0            0      1.6kb           832b\\ngreen  open   .kibana_1          jNXBc9tuT-WJbgs7u33hRA   1   1          1            0     10.1kb            5kb\\ngreen  open   full_articles      OerehVoVQmudtWq-ubaueQ   4   1          0            0      1.6kb           832b\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f'https://{host}:{port}/_cat/indices?v'\n",
    "response = requests.get(url, auth=auth)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_data(client, index_name, df, chunk_size=500):\n",
    "    for idx in tqdm(range(0, len(df), chunk_size)):\n",
    "        # Upload chunk_size number of rows at a time\n",
    "        subset_df = df.iloc[idx:idx + chunk_size]\n",
    "\n",
    "        actions = [\n",
    "            {\n",
    "                '_index': index_name,\n",
    "                '_id': row.id,\n",
    "                '_source': {\n",
    "                    key: value \n",
    "                    for key, value in row._asdict().items() \n",
    "                    if key not in ['Index', 'id']\n",
    "                }\n",
    "            }\n",
    "            for row in subset_df.itertuples()\n",
    "        ]\n",
    "\n",
    "        _, errors = bulk(client, actions, max_retries=2, request_timeout=100)\n",
    "        assert len(errors) == 0, errors\n",
    "\n",
    "    # Refresh the data\n",
    "    client.indices.refresh(index_name, request_timeout=1000)\n",
    "\n",
    "def find_top_k_chunks(\n",
    "    embeddings,\n",
    "    k,\n",
    "    cols_to_query,\n",
    "    index_name,\n",
    "    client,\n",
    "    emb_col,\n",
    "    chunk_size=500,\n",
    "):\n",
    "\n",
    "    req_head = {\"index\": index_name}\n",
    "    responses = []\n",
    "\n",
    "    for idx in range(0, len(embeddings), chunk_size):\n",
    "        subset_embeddings = embeddings[idx : idx + chunk_size]\n",
    "        request = []\n",
    "\n",
    "        for embedding in subset_embeddings:\n",
    "            req_body = {\n",
    "                \"query\": {\"knn\": {emb_col: {\"vector\": embedding, \"k\": k}}},\n",
    "                \"size\": k,\n",
    "                \"_source\": cols_to_query,\n",
    "            }\n",
    "\n",
    "            request.extend([req_head, req_body])\n",
    "\n",
    "        r = client.msearch(body=request)\n",
    "        responses.extend(r[\"responses\"])\n",
    "\n",
    "    # Post processing\n",
    "    chunks = []\n",
    "    for item in responses:\n",
    "        df = pd.DataFrame(item[\"hits\"][\"hits\"])\n",
    "        df = df[[\"_id\", \"_score\"]].join(pd.json_normalize(df[\"_source\"]))\n",
    "        chunks.append(df.to_dict(orient=\"records\"))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the train_index\n",
    "- Stores vectors for training the FAISS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'train_index'\n",
    "emb_col = 'embedding'\n",
    "emb_dim = len(articles.loc[0, emb_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'train_index'}\n"
     ]
    }
   ],
   "source": [
    "index_body = {\n",
    "    'settings': {\n",
    "        'index': {\n",
    "            'number_of_shards': 10,\n",
    "            'number_of_replicas': 0,\n",
    "            'refresh_interval': -1,\n",
    "        }\n",
    "    },\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            emb_col: { \n",
    "                'type': 'knn_vector',\n",
    "                'dimension': emb_dim\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "if client.indices.exists(index=index_name):\n",
    "    # Delete the index if it exists\n",
    "    client.indices.delete(index=index_name)\n",
    "\n",
    "response = client.indices.create(index_name, body=index_body)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [14:45<00:00,  4.52s/it]\n"
     ]
    }
   ],
   "source": [
    "upload_data(client, index_name='train_index', df=articles[['id', emb_col]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train FAISS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_id': 'faiss_ivf_pq', 'result': 'deleted'}\n",
      "{\"model_id\":\"faiss_ivf_pq\"}\n"
     ]
    }
   ],
   "source": [
    "model_name = 'faiss_ivf_pq'\n",
    "url = f'https://{host}:{port}/_plugins/_knn/models/{model_name}'\n",
    "\n",
    "payload = {\n",
    "    'training_index': index_name,\n",
    "    'training_field': emb_col,\n",
    "    'dimension': emb_dim,\n",
    "    'description': 'FAISS IVF-PQ ANN index',\n",
    "    'method': {\n",
    "        'name': 'ivf',\n",
    "        'engine': 'faiss',\n",
    "        'space_type': 'l2',\n",
    "        'parameters':{\n",
    "            'nlist': 2048,\n",
    "            'nprobes': 256,\n",
    "            'encoder':{\n",
    "                'name':'pq',\n",
    "                'parameters':{\n",
    "                    'code_size': 8,\n",
    "                    'm': 8\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "if requests.get(url, auth=auth).status_code != 404:\n",
    "    # Delete if model exists\n",
    "    response = requests.delete(url, auth=auth)\n",
    "    print(response.json())\n",
    "\n",
    "# Train the model\n",
    "response = requests.post(f'{url}/_train', json=payload, auth=auth)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poll the Training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-21 09:38:09 POLL: poll() calls check_success(False)\n",
      "2022-05-21 09:39:21 POLL: poll() calls check_success(False)\n",
      "2022-05-21 09:40:41 POLL: poll() calls check_success(False)\n",
      "2022-05-21 09:41:43 POLL: poll() calls check_success(False)\n",
      "2022-05-21 09:42:44 POLL: poll() calls check_success(False)\n",
      "2022-05-21 09:43:46 POLL: poll() calls check_success(False)\n",
      "2022-05-21 09:44:47 POLL: poll() calls check_success(False)\n",
      "2022-05-21 09:45:48 POLL: poll() calls check_success(False)\n",
      "2022-05-21 09:46:50 POLL: poll() calls check_success(False)\n",
      "2022-05-21 09:47:51 POLL: poll() calls check_success(False)\n",
      "2022-05-21 09:48:52 POLL: poll() calls check_success(False)\n",
      "2022-05-21 09:49:53 POLL: poll() calls check_success(False)\n",
      "2022-05-21 09:50:55 POLL: poll() calls check_success(False)\n",
      "2022-05-21 09:51:56 POLL: poll() calls check_success(True)\n"
     ]
    }
   ],
   "source": [
    "url = f'https://{host}:{port}/_plugins/_knn/models/{model_name}?filter_path=state&pretty'\n",
    "\n",
    "polling2.poll(\n",
    "    lambda: requests.get(url, auth=auth).json()['state'] != 'training',\n",
    "    step=60,\n",
    "    poll_forever=True,\n",
    "    log=POLL)\n",
    "\n",
    "training_status = requests.get(url, auth=auth).json()['state']\n",
    "assert training_status=='created', training_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the ANN Search Index with model trained in previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'sample_chunks'}\n"
     ]
    }
   ],
   "source": [
    "index_name = 'chunk_texts_index'\n",
    "index_body = {\n",
    "    'settings': {\n",
    "        'index': {\n",
    "            'knn': True,\n",
    "            'number_of_shards': 10,\n",
    "            'number_of_replicas': 0,\n",
    "            'refresh_interval': -1,\n",
    "        }\n",
    "    },\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            emb_col: {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": emb_dim,\n",
    "                \"method\": {\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"space_type\": \"l2\",\n",
    "                    \"engine\": \"nmslib\",\n",
    "                    \"parameters\": {\n",
    "                        \"ef_construction\": 128,\n",
    "                        \"m\": 24\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            # emb_col: { \n",
    "            #     'type': 'knn_vector',\n",
    "            #     'model_id': model_name,\n",
    "            # }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "if client.indices.exists(index=index_name):\n",
    "    # Delete the index if it exists\n",
    "    client.indices.delete(index=index_name)\n",
    "\n",
    "response = client.indices.create(index_name, body=index_body)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 977/977 [24:08<00:00,  1.48s/it]  \n"
     ]
    }
   ],
   "source": [
    "upload_data(client, index_name=index_name, df=articles, chunk_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'total': 10, 'successful': 10, 'failed': 0}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f'https://{host}:{port}/_plugins/_knn/warmup/{index_name}?pretty'\n",
    "response = requests.get(url, auth=auth)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'epoch': '1653099453', 'timestamp': '02:17:33', 'count': '97685'}]\n"
     ]
    }
   ],
   "source": [
    "# Check number of records after update\n",
    "print(client.cat.count(index_name, params={\"format\": \"json\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get(index=index_name, id='46683031823_6_Google')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query by search term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'google'\n",
    "num_results = 5\n",
    "\n",
    "query = {\n",
    "    'size': num_results,\n",
    "    'query': {\n",
    "        'multi_match': {\n",
    "            'query': q,\n",
    "            'fields': ['brand', 'title', 'text']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = client.search(\n",
    "    index=index_name,\n",
    "    body=query\n",
    ")\n",
    "\n",
    "assert len(response['hits']['hits'])==num_results\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things you can update\n",
    "num_results = 10 \n",
    "## Recommend to keep it <=100 for good search speed\n",
    "\n",
    "row_to_query = randint(0, len(articles)) \n",
    "## Choose a random integer between 0 and len(articles)\n",
    "\n",
    "cols_to_query = ['title', 'text'] \n",
    "## Valid options for cols_to_query are: ['pull_date', 'brand', 'article_id', 'text', 'title', 'estimatedPublishedDate', 'anti_trans_legislation', 'covid_19', 'cybersecurity', 'data_privacy_gdpr', 'diversity_inclusion', 'gen_z', 'inflation', 'minimum_wage', 'ukraine_russia', 'vaccine', 'waste_reduction', 'work_from_home']. The more columns you extract, the slower the query\n",
    "\n",
    "###################################################################\n",
    "\n",
    "# DO NOT CHANGE BELOW!\n",
    "index_name = 'chunk_text_index'\n",
    "emb_col = 'embedding'\n",
    "embeddings = [articles.loc[row_to_query, emb_col].tolist()]\n",
    "\n",
    "responses = find_top_k_chunks(\n",
    "    embeddings,\n",
    "    k=num_results,\n",
    "    cols_to_query=cols_to_query,\n",
    "    index_name=index_name,\n",
    "    client=client,\n",
    "    emb_col=\"embedding\",\n",
    "    chunk_size=500,\n",
    ")\n",
    "\n",
    "# Look at the output\n",
    "print('🔎 Query:')\n",
    "print(articles.loc[row_to_query, cols_to_query].values)\n",
    "print('\\n-------------------------------------------------------------\\n')\n",
    "print('📝 Results')\n",
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The opensearch documentation says score is a function of distance\n",
    "$$score = \\frac{1}{1+distance}$$\n",
    "\n",
    "So we can calculate the L2 distance using\n",
    "$$distance = \\frac{1}{score} - 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health status index              uuid                   pri rep docs.count docs.deleted store.size pri.store.size\n",
      "green  open   chunk_text_index   BBGZjZzvTzqGeE9OG_5xXg  10   0    3885306            0     39.7gb         39.7gb\n",
      "green  open   article_chunks     OoKSWT4ZRwuJoLvDcbeZVw   4   1          0            0      1.6kb           852b\n",
      "green  open   python-test-index3 zghM9fXRSJG_K8Nb5xJCOQ   4   1          0            0      1.6kb           832b\n",
      "green  open   .kibana_1          jNXBc9tuT-WJbgs7u33hRA   1   1          1            0     10.1kb            5kb\n",
      "green  open   full_articles      scnMPTNfTw2QuGTa4ZA88Q  10   0    3930943            0     15.5gb         15.5gb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = f'https://{host}:{port}/_cat/indices?v'\n",
    "response = requests.get(url, auth=auth)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "response = client.indices.delete(index='train_index')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "response = client.indices.delete(index='chunk_texts_index')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac0a39534e76755b8a1334574ec535bc535d522311fd20768e8d6305e7dda128"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ns')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
